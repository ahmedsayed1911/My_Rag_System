import streamlit as st
import os
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings.fastembed import FastEmbedEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate

# --- Safe replacement for missing LangChain function ---
def create_stuff_documents_chain(llm, prompt):
    """
    Custom simplified version of LangChain's create_stuff_documents_chain,
    compatible with older LangChain versions.
    """
    from langchain.chains import LLMChain
    from langchain.chains.combine_documents.base import BaseCombineDocumentsChain

    class SimpleCombineDocumentsChain(BaseCombineDocumentsChain):
        def _combine_docs(self, docs, **kwargs):
            # Ø¯Ù…Ø¬ Ø§Ù„Ù†ØµÙˆØµ ÙÙŠ Ø³ÙŠØ§Ù‚ ÙˆØ§Ø­Ø¯
            context = "\n\n".join([doc.page_content for doc in docs])
            # ØªØ´ØºÙŠÙ„ Ø§Ù„Ù€ LLMChain Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚
            return LLMChain(llm=llm, prompt=prompt).run(context=context, **kwargs)

    return SimpleCombineDocumentsChain(llm_chain=LLMChain(llm=llm, prompt=prompt))


# --- Safe replacement for create_retrieval_chain ---
def create_retrieval_chain(retriever, document_chain):
    """
    Manual version of LangChain's create_retrieval_chain
    for compatibility with older versions.
    """
    class SimpleRetrievalChain:
        def __init__(self, retriever, document_chain):
            self.retriever = retriever
            self.document_chain = document_chain

        def invoke(self, inputs):
            query = inputs.get("input", "")
            retrieved_docs = self.retriever.get_relevant_documents(query)
            answer = self.document_chain.combine_docs(retrieved_docs, input=query)
            return {
                "answer": answer,
                "context": retrieved_docs
            }

    return SimpleRetrievalChain(retriever, document_chain)


# --- Streamlit UI setup ---
st.set_page_config(page_title="My RAG System", page_icon="ğŸ¤–")
st.title("ğŸ“š My RAG System â€” Ask Your PDF")

# --- API Key ---
api_key = st.secrets.get("GROQ_API_KEY")
if not api_key:
    st.error("Please set your GROQ_API_KEY in Streamlit Secrets.")
    st.stop()

# --- Upload PDF ---
uploaded_file = st.file_uploader("ğŸ“„ Upload your PDF file", type="pdf")

if uploaded_file:
    with st.spinner("Processing your PDF..."):
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù€ PDF
        loader = PyPDFLoader(uploaded_file)
        docs = loader.load()

        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†ØµÙˆØµ Ø¥Ù„Ù‰ chunks
        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
        splits = splitter.split_documents(docs)

        # Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ¬Ù‡ÙŠØ©
        embedding = FastEmbedEmbeddings()
        vectorstore = Chroma.from_documents(splits, embedding=embedding)
        retriever = vectorstore.as_retriever()

        # ØªÙ‡ÙŠØ¦Ø© Ù†Ù…ÙˆØ°Ø¬ Groq (LLaMA 3.3)
        llm = ChatOpenAI(
            model="llama-3.3-70b-versatile",
            openai_api_base="https://api.groq.com/openai/v1",
            openai_api_key=api_key,
            temperature=0.5,
            max_tokens=512
        )

        # Ø¥Ø¹Ø¯Ø§Ø¯ prompt
        prompt = PromptTemplate.from_template("""
        Use the following context to answer the question.
        If you don't know the answer, just say "I don't know."

        Context:
        {context}

        Question: {input}
        """)

        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø³Ù„Ø§Ø³Ù„ ÙŠØ¯ÙˆÙŠÙ‹Ø§
        document_chain = create_stuff_documents_chain(llm, prompt)
        retrieval_chain = create_retrieval_chain(retriever, document_chain)

        st.success("âœ… PDF processed successfully!")

        # ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØ§Ù„Ø¬ÙˆØ§Ø¨
        question = st.text_input("ğŸ’¬ Ask a question about your PDF:")
        if st.button("Get Answer") and question:
            with st.spinner("ğŸ¤” Thinking..."):
                response = retrieval_chain.invoke({"input": question})
                st.write("### ğŸ¤– Answer:")
                st.write(response["answer"])

                # Ø¹Ø±Ø¶ Ø§Ù„Ù…ØµØ§Ø¯Ø± (Ø¥Ù† ÙˆØ¬Ø¯Øª)
                sources = response.get("context", None)
                if sources:
                    st.write("### ğŸ“š Sources used:")
                    for i, doc in enumerate(sources):
                        st.markdown(f"**Chunk {i+1}:** {doc.page_content[:300]}...")

else:
    st.info("â¬†ï¸ Please upload a PDF file to begin.")
